import { MessageContentType } from "@chatscope/use-chat/dist/enums";
// import {MessageContent} from "@chatscope/use-chat/dist/interfaces"
import {ChatMessage} from "@chatscope/use-chat/dist"; 

export enum OpenAIContentType {
  JSON = 10
}

export interface OpenAIBotMessage extends ChatMessage<MessageContentType>{

    /**
     * The reason the model stopped generating tokens. This will be `stop` if the model
     * hit a natural stop point or a provided stop sequence, `length` if the maximum
     * number of tokens specified in the request was reached, `content_filter` if
     * content was omitted due to a flag from our content filters, `tool_calls` if the
     * model called a tool, or `function_call` (deprecated) if the model called a
     * function.
     */
    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';
  
    // content: string | null;
    // // content: TextContent | OpenAIStructuredContent | null
    // // content: React.ReactNode;

    /**
     * The index of the choice in the list of choices.
     */
    index: number;

    /**
     * The refusal message generated by the model.
     */
    refusal: string | null;

  };

  export interface OpenAIMessageReceivedType {
    (created: Date, conversationId: string, messages: Array<OpenAIBotMessage>, sender: unknown): void;
  }

  export interface OpenAIGeneratingMessageType {
    (conversationId: string, userId: string): void;
  }
  
export type TextualChatMessage = ChatMessage<MessageContentType.TextPlain | MessageContentType.TextMarkdown| MessageContentType.TextHtml>

export enum OpenAIMessagePhase {
  AskUserFeelings = 0,
  AnalyzeFeelings = 1
}